import os
import uuid
import json
from app.conversation_logger import ConversationLogger
from livekit.agents import Agent
from app.mcp_tools.save_user import mcp  # MCP server
import asyncio
from typing import AsyncIterable
from datetime import datetime
import pytz

class AssistantAgent(Agent):
    def __init__(self, prompt_file: str, log_file: str = "chat_log.json"):
        instructions = self._load_prompt(prompt_file)
        super().__init__(instructions=instructions)

        self.mcp = mcp
        self.user_sessions = {}  # user_id -> sessionId

        # --- t·∫°o file log n·∫øu ch∆∞a c√≥ ---
        self.logger = ConversationLogger(log_file)
        self.current_response = ""  # Buffer ƒë·ªÉ t√≠ch l≈©y output realtime


    def get_current_time(self, tz_name="Asia/Ho_Chi_Minh"):
        tz = pytz.timezone(tz_name)
        return datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

    # --- Load prompt v√† inject current_time ---
    def _load_prompt(self, prompt_file: str) -> str:
        file_path = os.path.join(
            "/root/AGENT/TeleMedician/prompts", prompt_file
        )
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y prompt file: {file_path}")
        with open(file_path, "r", encoding="utf-8") as f:
            template = f.read()

        # Inject current time v√†o placeholder {current_time}
        current_time = self.get_current_time()
        prompt_filled = template.format(current_time=current_time)
        return prompt_filled

    # --- Override transcription_node ƒë·ªÉ print v√† log output realtime ---
    async def transcription_node(self, text: AsyncIterable[str], model_settings=None) -> AsyncIterable[str]:
        self.current_response = ""
        async for chunk in text:
            self.current_response += chunk
            print(chunk, end='', flush=True)  # Print realtime (kh√¥ng xu·ªëng d√≤ng)
            yield chunk
        print()  # Xu·ªëng d√≤ng khi ho√†n th√†nh
        self.logger.log("agent", self.current_response)  # Log full text khi done
        self.current_response = ""
        
    async def on_user_message(self, message: str, participant=None):
        print(f"üó£Ô∏è User said: {message}")
        self.logger.log("user", message)

        # G·ª≠i v√†o pipeline LLM
        bot_resp_obj = await self.process_input(message)
        await bot_resp_obj  # ch·ªù TTS n√≥i xong
        
            # --- X·ª≠ l√Ω input user (text tr·ª±c ti·∫øp, n·∫øu d√πng) ---
    async def process_user_text(self, user_text: str):
        print(f"User: {user_text}")  # Print input realtime
        self.logger.log("user", user_text)  # Log input

        # Process v·ªõi Agent (output s·∫Ω ƒë∆∞·ª£c handle b·ªüi transcription_node)
        bot_resp_obj = await super().process_input(user_text)
        await bot_resp_obj  # Ch·ªù speech done (n·∫øu c·∫ßn coordinate)

        return bot_resp_obj  # Tr·∫£ v·ªÅ object n·∫øu c·∫ßn

    # --- Khi user v√†o phi√™n (greeting s·∫Ω ƒë∆∞·ª£c handle b·ªüi transcription_node) ---
    async def on_enter(self):
        print("‚úÖ on_enter() ƒë∆∞·ª£c g·ªçi!")
        await asyncio.sleep(0.5)

        greeting_obj = await self.session.generate_reply(
            instructions="B·∫°n l√† tr·ª£ l√Ω y khoa c·ªßa True doc, b·∫°n chuy√™n ƒë·∫∑t l·ªãch kh√°m, h√£y ch√†o h·ªèi kh√°ch h√†ng th√¢n thi·ªán v√† kh√¥ng qu√° d√†i d√≤ng."
        )
        await greeting_obj  # Ch·ªù done (output ƒë√£ print/log realtime qua node)