import os
import uuid
import json
from app.conversation_logger import ConversationLogger
from livekit.agents import Agent
from app.mcp_tools.save_user import mcp  # MCP server
import asyncio
from typing import AsyncIterable
from datetime import datetime
import pytz

class AssistantAgent(Agent):
    def __init__(self, prompt_file: str, log_file: str = "chat_log.json"):
        instructions = self._load_prompt(prompt_file)
        super().__init__(instructions=instructions)

        self.mcp = mcp
        self.user_sessions = {}  # user_id -> sessionId

        # --- t·∫°o file log n·∫øu ch∆∞a c√≥ ---
        self.logger = ConversationLogger(log_file)
        self.current_response = ""  # Buffer ƒë·ªÉ t√≠ch l≈©y output realtime


    def get_current_time(self, tz_name="Asia/Ho_Chi_Minh"):
        tz = pytz.timezone(tz_name)
        return datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")

    # --- Load prompt v√† inject current_time ---
    def _load_prompt(self, prompt_file: str) -> str:
        file_path = os.path.join(
            "/root/AGENT/Tele_Medician/prompts", prompt_file
        )
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y prompt file: {file_path}")
        with open(file_path, "r", encoding="utf-8") as f:
            template = f.read()

        # Inject current time v√†o placeholder {current_time}
        current_time = self.get_current_time()
        prompt_filled = template.format(current_time=current_time)
        return prompt_filled

    # --- Override transcription_node ƒë·ªÉ print v√† log output realtime ---
    async def transcription_node(self, text: AsyncIterable[str], model_settings=None) -> AsyncIterable[str]:
        self.current_response = ""
        async for chunk in text:
            self.current_response += chunk
            print(chunk, end='', flush=True)  # Print realtime (kh√¥ng xu·ªëng d√≤ng)
            yield chunk
        print()  # Xu·ªëng d√≤ng khi ho√†n th√†nh
        self.logger.log("agent", self.current_response)  # Log full text khi done
        self.current_response = ""
        
    async def on_user_message(self, message: str, participant=None):
        print(f"üó£Ô∏è User said: {message}")
        self.logger.log("user", message)

        # G·ª≠i v√†o pipeline LLM
        bot_resp_obj = await self.process_input(message)
        await bot_resp_obj  # ch·ªù TTS n√≥i xong
        
            # --- X·ª≠ l√Ω input user (text tr·ª±c ti·∫øp, n·∫øu d√πng) ---
    async def process_user_text(self, user_text: str):
        print(f"User: {user_text}")  # Print input realtime
        self.logger.log("user", user_text)  # Log input

        # Process v·ªõi Agent (output s·∫Ω ƒë∆∞·ª£c handle b·ªüi transcription_node)
        bot_resp_obj = await super().process_input(user_text)
        await bot_resp_obj  # Ch·ªù speech done (n·∫øu c·∫ßn coordinate)

        return bot_resp_obj  # Tr·∫£ v·ªÅ object n·∫øu c·∫ßn

    # --- Khi user v√†o phi√™n (greeting s·∫Ω ƒë∆∞·ª£c handle b·ªüi transcription_node) ---
    async def on_enter(self):
        print("‚úÖ on_enter() ƒë∆∞·ª£c g·ªçi!")
        await asyncio.sleep(0.5)

        greeting_obj = await self.session.generate_reply(
            instructions="B·∫°n l√† tr·ª£ l√Ω y khoa, b·∫°n chuy√™n ƒë·∫∑t l·ªãch kh√°m, h√£y ch√†o h·ªèi kh√°ch h√†ng th√¢n thi·ªán v√† kh√¥ng qu√° d√†i d√≤ng."
        )
        await greeting_obj  # Ch·ªù done (output ƒë√£ print/log realtime qua node)


        # --- Override process_input ƒë·ªÉ handle khi model tr·∫£ r·ªóng ---
    async def process_input(self, message: str, **kwargs):
        """
        X·ª≠ l√Ω input ng∆∞·ªùi d√πng, c√≥ timeout & fallback n·∫øu model kh√¥ng tr·∫£ v·ªÅ g√¨.
        """
        try:
            # ‚úÖ Gi·ªõi h·∫°n th·ªùi gian x·ª≠ l√Ω, tr√°nh treo v√¥ h·∫°n
            response_obj = await asyncio.wait_for(
                super().process_input(message, **kwargs),
                timeout=20,  # gi√¢y, t√πy b·∫°n
            )

            # --- N·∫øu model tr·∫£ v·ªÅ m√† kh√¥ng c√≥ n·ªôi dung ---
            if not self.current_response.strip():
                fallback_msg = "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu √Ω b·∫°n. B·∫°n c√≥ th·ªÉ n√≥i l·∫°i r√µ h∆°n kh√¥ng?"
                print(f"[‚ö†Ô∏è No response content] {fallback_msg}")
                self.logger.log("agent", fallback_msg)

                if hasattr(self, "session"):
                    reply = await self.session.generate_reply(instructions=fallback_msg)
                    await reply
                    return reply

            return response_obj

        except asyncio.TimeoutError:
            # ‚úÖ Tr∆∞·ªùng h·ª£p LLM kh√¥ng ph·∫£n h·ªìi trong th·ªùi gian cho ph√©p
            print("[‚è∞ Timeout] Model kh√¥ng ph·∫£n h·ªìi, chuy·ªÉn sang fallback.")
            fallback_msg = "Xin l·ªói, h·ªá th·ªëng ph·∫£n h·ªìi ch·∫≠m. B·∫°n c√≥ th·ªÉ n√≥i l·∫°i gi√∫p t√¥i kh√¥ng?"
            self.logger.log("agent", fallback_msg)

            if hasattr(self, "session"):
                reply = await self.session.generate_reply(instructions=fallback_msg)
                await reply
                return reply

        except Exception as e:
            # ‚úÖ Tr∆∞·ªùng h·ª£p l·ªói kh√°c (network, SDK, etc)
            print(f"[‚ùå process_input error]: {e}")
            fallback_msg = "H·ªá th·ªëng ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau √≠t ph√∫t."
            self.logger.log("agent", fallback_msg)

            if hasattr(self, "session"):
                reply = await self.session.generate_reply(instructions=fallback_msg)
                await reply
                return reply

        return None
    
    

